import torch
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments,
)
from peft import LoraConfig
from trl import SFTTrainer

# 1. é…ç½®è·¯å¾„å’Œå‚æ•°
model_name = "./models/Qwen/Qwen2.5-7B-Instruct" # æˆ–è€…æœ¬åœ°è·¯å¾„
new_model_name = "Qwen2.5-Medical-LoRA"
dataset_file = "medical_sft_data.jsonl"

# 2. åŠ è½½é‡åŒ–é…ç½® (4-bit QLoRAï¼Œæ˜¾å­˜å ç”¨æä½)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

# 3. åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token # ä¿®å¤ pad token é—®é¢˜

# 4. é…ç½® LoRA
peft_config = LoraConfig(
    r=16,       # LoRA ç§©ï¼Œè¶Šå¤§å‚æ•°è¶Šå¤š
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"] # é’ˆå¯¹ Qwen çš„å…¨æ¨¡å—å¾®è°ƒ
)

# 5. åŠ è½½æ•°æ®é›†
dataset = load_dataset("json", data_files=dataset_file, split="train")

# 6. é…ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=1,          # æ¼”ç¤ºç”¨ 1 epochï¼Œå®é™…å»ºè®® 3-5
    # ============================================================
    # ğŸ‘‡ å¿…é¡»ä¿®æ”¹è¿™ 3 è¡Œæ¥æ‹¯æ•‘æ˜¾å­˜
    # ============================================================
    per_device_train_batch_size=1,       # âŒ åŸæ¥æ˜¯ 4 -> æ”¹ä¸º 1 (æœ€å…³é”®)
    gradient_accumulation_steps=4,       # âŒ åŸæ¥æ˜¯ 1 -> æ”¹ä¸º 4 (ä¿æŒæ€»æ‰¹æ¬¡ä¸å˜)
    gradient_checkpointing=True,         # âœ… å¿…é¡»æ–°å¢è¿™ä¸€è¡Œï¼(ç”¨æ—¶é—´æ¢ç©ºé—´ï¼Œçœæ˜¾å­˜ç¥å™¨)
    # ============================================================
    learning_rate=2e-4,
    weight_decay=0.001,
    fp16=True,
    logging_steps=25,
    report_to="tensorboard",
    save_steps=100,
    optim="paged_adamw_32bit",   # èŠ‚çœæ˜¾å­˜çš„å…³é”®ä¼˜åŒ–å™¨
)

# ==========================================
# 7. å¼€å§‹è®­ç»ƒ (ä¿®æ­£ç‰ˆ)
# ==========================================

# 1. å®šä¹‰æ ¼å¼åŒ–å‡½æ•°ï¼šæŠŠæ•°æ®æ‹¼æˆ Qwen çš„å¯¹è¯æ ¼å¼
def formatting_prompts_func(example):
    output_texts = []
    # éå†æ•°æ®é›†ä¸­çš„æ¯ä¸€æ¡
    for i in range(len(example['instruction'])):
        # æ„å»º ChatML æ ¼å¼: <|im_start|>role...<|im_end|>
        text = (
            f"<|im_start|>system\n{example['instruction'][i]}<|im_end|>\n"
            f"<|im_start|>user\n{example['input'][i]}<|im_end|>\n"
            f"<|im_start|>assistant\n{example['output'][i]}<|im_end|>"
        )
        output_texts.append(text)
    return output_texts

# 2. åˆå§‹åŒ– Trainer
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    peft_config=peft_config,
    formatting_func=formatting_prompts_func, # âœ… ä½¿ç”¨è‡ªå®šä¹‰çš„æ‹¼æ¥å‡½æ•°
    # dataset_text_field="output",           # âŒ åˆ æ‰è¿™è¡Œï¼Œå¦åˆ™ä¼šå†²çª
    tokenizer=tokenizer,
    args=training_args,
    max_seq_length=512,
)

print("ğŸš€ å¼€å§‹å¾®è°ƒ...")
trainer.train()

# 8. ä¿å­˜å¾®è°ƒåçš„é€‚é…å™¨ (Adapter)
trainer.model.save_pretrained(new_model_name)
print(f"âœ… å¾®è°ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜è‡³ {new_model_name}")